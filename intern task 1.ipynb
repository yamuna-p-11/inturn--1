{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76406f5b-410e-490d-a378-713dd078dc5f",
   "metadata": {},
   "source": [
    "***DATA PIPELINE DEVELOPMENT***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9676431d-e6c3-4836-b504-9556b6636c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1aac67ae-b965-40f7-999d-b0a5c4cb8aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data Preview:\n",
      "    ID     Name  Age  Gender           City  Income Education Marital_Status  \\\n",
      "0   1    Alice   25  Female       New York   50000  Bachelor         Single   \n",
      "1   2      Bob   30    Male    Los Angeles   60000    Master        Married   \n",
      "2   3  Charlie   35    Male        Chicago   70000       PhD        Married   \n",
      "3   4    Diana   40  Female  San Francisco   55000  Bachelor       Divorced   \n",
      "4   5    Ethan   28    Male        Seattle   62000    Master         Single   \n",
      "\n",
      "          Occupation  Loan_Amount  ...  Work_Hours  Screen_Time  \\\n",
      "0           Engineer        10000  ...           8            5   \n",
      "1             Doctor        15000  ...           9            4   \n",
      "2          Scientist        20000  ...           7            6   \n",
      "3             Artist        12000  ...           7            5   \n",
      "4  Software Engineer        18000  ...           9            3   \n",
      "\n",
      "   Depression_Score Anxiety_Level Job_Satisfaction  Happiness_Score  \\\n",
      "0                 2             3                7                8   \n",
      "1                 3             4                6                7   \n",
      "2                 1             2                8                9   \n",
      "3                 3             4                5                6   \n",
      "4                 2             3                9                9   \n",
      "\n",
      "   Physical_Activity  Heart_Rate  Blood_Pressure  Diabetes_Risk  \n",
      "0                  4          72          120/80            Low  \n",
      "1                  5          75          130/85         Medium  \n",
      "2                  6          70          125/82            Low  \n",
      "3                  4          78          118/79         Medium  \n",
      "4                  7          74          122/81            Low  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load the dataset\n",
    "data = pd.read_csv(\"D:/intern.csv\")  # Ensure data.csv is in the same directory\n",
    "print(\"Original Data Preview:\\n\", data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f75d27b-6dd6-4cc1-827d-d5d9b7c30762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Categorical Columns: ['Gender', 'City', 'Education', 'Marital_Status', 'Occupation', 'Device_Type', 'Subscription_Type', 'Blood_Pressure']\n",
      "Numerical Columns: ['ID', 'Age', 'Income', 'Loan_Amount', 'Credit_Score', 'Spending_Score', 'Internet_Usage', 'Health_Score', 'Exercise_Hours', 'Sleep_Hours', 'Stress_Level', 'Social_Media_Usage', 'Mobile_Usage', 'Work_Hours', 'Screen_Time', 'Depression_Score', 'Anxiety_Level', 'Job_Satisfaction', 'Happiness_Score', 'Physical_Activity', 'Heart_Rate']\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Identify categorical and numerical columns\n",
    "categorical_cols = data.select_dtypes(include=[\"object\"]).columns.drop([\"Name\", \"Diabetes_Risk\"], errors=\"ignore\")\n",
    "numerical_cols = data.select_dtypes(exclude=[\"object\"]).columns\n",
    "\n",
    "print(\"\\nCategorical Columns:\", list(categorical_cols))\n",
    "print(\"Numerical Columns:\", list(numerical_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0eed06ee-4d7a-498c-8eeb-c7283fca5c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Features Before Processing:\n",
      "    ID  Age  Gender           City  Income Education Marital_Status  \\\n",
      "0   1   25  Female       New York   50000  Bachelor         Single   \n",
      "1   2   30    Male    Los Angeles   60000    Master        Married   \n",
      "2   3   35    Male        Chicago   70000       PhD        Married   \n",
      "3   4   40  Female  San Francisco   55000  Bachelor       Divorced   \n",
      "4   5   28    Male        Seattle   62000    Master         Single   \n",
      "\n",
      "          Occupation  Loan_Amount  Credit_Score  ...  Mobile_Usage  \\\n",
      "0           Engineer        10000           750  ...             6   \n",
      "1             Doctor        15000           800  ...             7   \n",
      "2          Scientist        20000           820  ...             5   \n",
      "3             Artist        12000           770  ...             8   \n",
      "4  Software Engineer        18000           780  ...             6   \n",
      "\n",
      "   Work_Hours Screen_Time Depression_Score  Anxiety_Level  Job_Satisfaction  \\\n",
      "0           8           5                2              3                 7   \n",
      "1           9           4                3              4                 6   \n",
      "2           7           6                1              2                 8   \n",
      "3           7           5                3              4                 5   \n",
      "4           9           3                2              3                 9   \n",
      "\n",
      "   Happiness_Score  Physical_Activity  Heart_Rate  Blood_Pressure  \n",
      "0                8                  4          72          120/80  \n",
      "1                7                  5          75          130/85  \n",
      "2                9                  6          70          125/82  \n",
      "3                6                  4          78          118/79  \n",
      "4                9                  7          74          122/81  \n",
      "\n",
      "[5 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Define the target column (optional)\n",
    "target_column = \"Diabetes_Risk\"  # Change if needed\n",
    "if target_column in data.columns:\n",
    "    X = data.drop([target_column, \"Name\"], axis=1, errors=\"ignore\")  # Drop non-essential columns\n",
    "    y = data[target_column]\n",
    "else:\n",
    "    X = data.drop([\"Name\"], axis=1, errors=\"ignore\")  # No target column\n",
    "    y = None\n",
    "\n",
    "print(\"\\nFeatures Before Processing:\\n\", X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "450af085-0627-4cf6-b175-1792d15eab61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Define preprocessing steps\n",
    "num_imputer = SimpleImputer(strategy=\"mean\")  # Fill missing numerical values with mean\n",
    "cat_imputer = SimpleImputer(strategy=\"most_frequent\")  # Fill missing categorical values with most frequent\n",
    "encoder = OneHotEncoder(handle_unknown=\"ignore\")  # Convert categorical values to numeric\n",
    "scaler = StandardScaler()  # Standardize numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6400dbb9-0f54-4eef-8482-2558498849cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Create a ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", Pipeline([(\"imputer\", num_imputer), (\"scaler\", scaler)]), numerical_cols),\n",
    "        (\"cat\", Pipeline([(\"imputer\", cat_imputer), (\"encoder\", encoder)]), categorical_cols),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Step 6: Apply the pipeline\n",
    "pipeline = Pipeline([\n",
    "    (\"preprocessing\", preprocessor)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b10f45eb-7af7-49da-a6be-cc5e1d7a3b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Data Shape: (8, 29)\n",
      "Testing Data Shape: (2, 29)\n",
      "\n",
      "Processed Training Data Sample:\n",
      "          0         1         2         3         4         5         6   \\\n",
      "0  0.185695  0.038490 -0.268024 -0.902794 -1.194476 -1.118862 -1.375048   \n",
      "1 -1.671258 -1.193191 -1.277056 -1.109147 -0.670870  0.946729  0.825029   \n",
      "2  0.928477 -0.885270 -0.772540 -0.283735 -0.278166 -0.774597 -0.641689   \n",
      "3 -0.928477  0.346410  1.245524  0.954382  1.161751  0.258199  0.091670   \n",
      "4  1.671258 -0.577350 -0.394153 -0.490088 -0.932673 -1.463127 -1.375048   \n",
      "\n",
      "         7         8         9   ...   49   50   51   52   53   54   55   56  \\\n",
      "0 -1.097260 -1.441153 -1.341641  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1  0.399004  0.480384  0.447214  ...  1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0   \n",
      "2 -0.299253 -0.160128 -0.447214  ...  0.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0   \n",
      "3  0.698257 -0.160128  1.341641  ...  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0   \n",
      "4 -1.596015 -0.800641 -1.341641  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "\n",
      "    57   58  \n",
      "0  0.0  1.0  \n",
      "1  0.0  0.0  \n",
      "2  0.0  0.0  \n",
      "3  0.0  0.0  \n",
      "4  1.0  0.0  \n",
      "\n",
      "[5 rows x 59 columns]\n",
      "\n",
      "Processed Testing Data Sample:\n",
      "          0         1         2         3         4         5         6   \\\n",
      "0  1.299867  2.655811  2.506814  3.017911  2.470766  1.290994  2.291746   \n",
      "1 -1.299867 -0.423390 -0.015766 -0.077382  0.638145 -0.430331 -0.641689   \n",
      "\n",
      "         7         8         9   ...   49   50   51   52   53   54   55   56  \\\n",
      "0  1.695766  2.401922  2.236068  ...  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1  0.897758  1.120897 -0.447214  ...  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "\n",
      "    57   58  \n",
      "0  0.0  0.0  \n",
      "1  0.0  0.0  \n",
      "\n",
      "[2 rows x 59 columns]\n",
      "\n",
      "✅ Pipeline executed successfully! Processed training and test data saved.\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Split data if target column exists\n",
    "if y is not None:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    print(\"\\nTraining Data Shape:\", X_train.shape)\n",
    "    print(\"Testing Data Shape:\", X_test.shape)\n",
    "\n",
    "    X_train_transformed = pipeline.fit_transform(X_train)\n",
    "    X_test_transformed = pipeline.transform(X_test)\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    processed_train_data = pd.DataFrame(X_train_transformed)\n",
    "    processed_test_data = pd.DataFrame(X_test_transformed)\n",
    "\n",
    "    # Save the processed data\n",
    "    processed_train_data.to_csv(\"processed_train.csv\", index=False)\n",
    "    processed_test_data.to_csv(\"processed_test.csv\", index=False)\n",
    "\n",
    "    print(\"\\nProcessed Training Data Sample:\\n\", processed_train_data.head())\n",
    "    print(\"\\nProcessed Testing Data Sample:\\n\", processed_test_data.head())\n",
    "\n",
    "    print(\"\\n✅ Pipeline executed successfully! Processed training and test data saved.\")\n",
    "else:\n",
    "    # If no target column, apply transformations to the whole dataset\n",
    "    processed_data = pipeline.fit_transform(X)\n",
    "    processed_df = pd.DataFrame(processed_data)\n",
    "\n",
    "    # Save the transformed data\n",
    "    processed_df.to_csv(\"processed_data.csv\", index=False)\n",
    "\n",
    "    print(\"\\nProcessed Data Sample:\\n\", processed_df.head())\n",
    "    print(\"\\n✅ Pipeline executed successfully! Processed data saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3cb797-64a6-4e52-9b32-dbd6a89bbc30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
